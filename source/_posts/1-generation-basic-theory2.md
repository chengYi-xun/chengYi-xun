---
title: 笔记｜生成模型（二）：生成模型的技术路线总览
date: 2025-08-04 01:37:31
cover: false
mathjax: true
categories:
 - Notes
tags:
 - Deep learning
 - Generative models theory
series: Diffusion Models theory
---

## 判别模型 vs 生成模型

在人工智能领域，如今深度学习模型大致可分为两类：判别式模型（Discriminative Models）和生成式模型（Generative Models）。

**判别模型**:

判别模型关注的是建模条件概率 $P(y \mid x)$，即在给定输入 $x$ 的条件下预测标签 $y$。从信息学角度来看，人类所使用的语言、图像、音频等形式的信息，虽然本质上处于极高维空间中，但它们在该空间中的分布往往集中在结构性很强、低维的流形上。因此，它们在高维空间中呈现出几何稀疏性，换句话说，数据在高维空间中运动、变化，但只活动在某种低自由度的结构中。举个栗子：假设我们用 $64×64×3=12288$ 维来表示彩色人脸图像，但现实中，人脸受限于：姿态（2～3个自由度），表情（2～5个自由度），光照变化，年龄、性别等特征。尽管图像空间是 1 万多维，人脸变化的真实自由度可能只有几十个维度，所以，所有可能的 RGB 图像中，人脸图像只占据一个非常小的“面团”一样的区域，这个区域是一个低维流形。

很多人对低维流形可能理解的还是不够形象，举一个更抽象的例子就是：想象一只虫子在一张纸上爬，纸是 2D的，但纸卷成球、筒或任何弯曲形状时，虫子仍然只能沿着纸的表面爬。如果虫子位置用 3D 坐标表示，它的“位置向量”是在 3D 空间中表示的，但所有点都集中在那张弯曲的纸上，所以实际虫子的坐标可以用二维坐标方式表示就足够了。而这张纸就是一个二维流形嵌入在三维空间中。

经过上述例子说明，我们可以发现真实世界的数据分布在一个高维空间但稠密且低维的流形上，而不同类别的数据通常分布在这个流形上的不同区域。因此，判别模型的目标就是：在这个复杂的高维空间中，学习一个最优的决策边界（可能是非线性的），从而将不同类别的流形区域尽可能清晰、稳定地区分开。这个边界可以是：一条直线（线性模型），一个超平面（SVM），一个高度复杂的非线性判别函数（如 ResNet、Transformer）等。

数学语言表达：

假设样本 $x \in R^d$，类别标签为 $y \in \{1, 2, \dots, K\}$

判别模型试图学习一个函数 $f(x)$，使得：

$$f(x) = \mathop {\arg \max }\limits_y \;P(y\mid x)$$

**生成模型**:

生成模型则试图学习数据的联合概率分布 $P(x, y)$ 或边际概率分布 $P(x)$。它们不仅可以完成判别任务（通过 $P(y \mid x) = \frac{P(x, y)}{P(x)}$），更重要的是能够生成与训练数据“相似”的新数据样本。换句话说：

- 判别模型关注“这张图是猫吗？”
- 生成模型尝试“生成一张像猫的图”。

所以，[生成模型的一般定义是](https://zhuanlan.zhihu.com/p/611466195)：给定从真实分布 $P(x)$ 中采样的观测数据 $x$，训练得到一个由参数 $\theta$ 控制、能够逼近真实分布的模型 $p_\theta(x)$，我们将 $p_\theta(x)$ 称为生成模型。通常，$x$ 可以被视为来自某一分布的样本，例如一组图像数据，其中每一张图片可以看作是一个多维向量。$P(x)$ 表示这些数据在真实世界中的分布；而我们能够观测到的数据，只是从该真实分布中采样而来。

需要注意的是，真实分布 $P(x)$ 通常是无法直接获取的。即使在一个看似简单的问题中，比如抛硬币，表面上我们可能观察到正反面概率为 50%，但实际上决定这个概率的因素非常复杂，例如空气阻力、抛掷的力度与角度，甚至太阳风和地磁等微妙因素都可能影响最终的落地结果。

因此，真实分布往往是高度复杂、不可观测的。生成模型 $p_\theta(x)$ 的任务就是用某种近似方法对 $P(x)$ 进行建模。例如，在抛硬币的例子中，我们可以简化建模为一个由参数 $\theta$ 控制的伯努利分布，通过参数估计的方法求出 $\theta$；也可以引入更多特征（如力度、角度等）构建一个更精细的模型。

在得到生成模型 $ P_\theta(x) $ 后，就能采样（生成）出各式各样的，包括观测集没有的数据了，这就是最终的目的。

但我们无法直接用神经网络拟合 $P_\theta(x)$，一方面是因为真值难以构造，我们无法穷尽每类图像在图像空间中的概率函数是什么，因此就无法计算每类图像的真值。另一方面，概率密度函数 $P_\theta(x)$ 通常定义在高维空间中，在这种空间中直接建模密度函数的形式极为复杂且不稳定（还稀疏和不连续）。尤其对于图像这样的高维数据，直接在这样上万维度的空间上建模一个可归一化的概率密度函数既计算复杂，又缺乏明确的分布形态。

有些**大聪明**不服，马上跳出来了：“你说的不对，直接用文本输入，然后用图片做监督，比如我给我网络输入一个‘草地上有一只猫’，然后我用草地上的猫来监督他的训练。只要我的图片数量够多，不就可以让网络学会‘草地上有只猫’图像的概率分布函数了吗”。很好，你有点小聪明，但是不多。首先是不管你穷尽多少图像，都无法穷举该类型的照片，自然就无法学习到他的概率。真实情况也确实是如果我们能够捏造某种类型的数据便已足够。但第二个问题是，这种做法会导致**均值灾难**。

什么是均值灾难？以上面的例子为例，你训练集里确实有10万张猫在草地上的照片，但这些猫位置不同、大小不同、颜色不同。用像素级的均方误差来监督网络训练——也就是说，你在惩罚网络生成图像和真实图像之间的逐像素差异。

于是，发生悲剧了：网络为了在所有训练图像上都“少犯错”，它学会了一个所有可能图像的平均值。也就是说，猫的位置模糊了、轮廓糊了、颜色灰了——整个图像看起来就像是一只幽灵猫，像被拍糊了一样，完全丧失了真实感。这就是均值灾难（mean collapse）或模糊灾难（blurry image problem）。

它的本质是什么？本质是你让神经网络输出一个“确定的图像”，去逼近一个多峰分布的真值。这时候，神经网络做的事情就是——输出这个多峰分布的均值图像。但问题是，多峰分布的均值，根本不是任何一个真实样本，它只是各个样本的“中间态”，而这个“中间态”在图像空间里看起来就是一张糊图。


## 那如何训练生成模型呢

看过之前笔记的同学应该还记的变分推断这一好用的工具（[(=`ω´=)我是链接猪](../0-generation-basic-theory)）。没错，既然无法直接求出真实数据的分布 $P(x)$，那我们就尝试近似它。生成模型大体上做的事情就是：

从一个简单的已知分布（如标准高斯分布）出发，通过某种方式或手段，将其近似为真实数据的概率分布 $P(x)$ 。更抽象地说，这个变换相当于把原始的低维流形通过一个映射函数 $f(z)$ 映射到高维的数据空间。这样做的好处是：我们可以在简单的分布 $P(z)$ 中轻松地进行随机采样，然后通过学习得到的生成函数 $f(z)$，生成看起来像来自真实数据分布 $P(x)$ 的样本。

所以，根据上述手段和方式的不同，生成模型划分为多个流派和类别。


| **大类** | **流派 (派系)** | **核心思想** | **代表性模型 / 算法** | **开创性/代表性论文** |  
| :--- | :--- | :--- | :--- | :--- |  
| **隐式建模 (Implicit Modeling)** | **对抗生成 (Adversarial)** | 通过生成器和判别器之间的零和博弈来学习数据分布，最终生成器产生无法被判别器区分的逼真样本。 | GAN, WGAN | **[Generative Adversarial Nets (2014)](https://arxiv.org/abs/1406.2661)** - *Ian Goodfellow, et al.* <br> **[Wasserstein GAN (2017)](https://arxiv.org/abs/1701.07875)** - *Martin Arjovsky, et al.* |  
| **显式建模 (Explicit Modeling)** | **扩散模型 (Diffusion Models)** | **前向过程**：对真实数据逐步添加噪声。**反向过程**：学习一个神经网络，从纯噪声开始，逐步去除噪声，最终“还原”出清晰的样本。 | DDPM, Score-based Generative Models | **[Denoising Diffusion Probabilistic Models (2020)](https://arxiv.org/abs/2006.11239)** - *Jonathan Ho, et al.* |  
| | **流模型 (Flow-based)** | 利用一系列**可逆变换**将简单分布直接映射到复杂的数据分布，从而可以精确计算出样本的概率密度（Likelihood）。 | NICE, RealNVP, Glow | **[NICE: Non-linear Independent Components Estimation (2014)](https://arxiv.org/abs/1410.8516)** - *Laurent Dinh, et al.* <br> **[Glow: Generative Flow with Invertible 1x1 Convolutions (2018)](https://arxiv.org/abs/1807.03039)** - *Diederik P. Kingma, et al.* |  
| | **流匹配 (Flow Matching)** | **直接学习**从简单分布（如噪声）到数据分布的连续变换**向量场**（Vector Field）。它无需像流模型那样强制变换可逆，也无需像扩散模型那样遵循固定的前向过程，实现了更高效和灵活的训练。 | Flow Matching, Conditional Flow Matching | **[Flow Matching for Generative Modeling (2022)](https://arxiv.org/abs/2210.02747)** - *Yaron Lipman, et al.* |  
| | **分数匹配 (Score Matching)** | 不直接对概率密度 $p(x)$ 建模，而是对其**对数概率的梯度** $\nabla_x \log p(x)$（分数函数）进行建模，并指导生成过程。 | NCSN (Noise Conditional Score Network) | **[Generative Modeling by Estimating Gradients of the Data Distribution (2019)](https://arxiv.org/abs/1907.05600)** - *Yang Song, et al.* |  
| | **自回归模型 (Autoregressive)** | 将数据的联合概率分布分解为一系列**条件概率的乘积**，并逐个维度地生成数据。 | PixelRNN, PixelCNN, VQ-VAE, WaveNet | **[Pixel Recurrent Neural Networks (2016)](https://arxiv.org/abs/1601.06759)** - *Aaron van den Oord, et al.* |  
| | **变分自编码器 (Variational Autoencoder)** | 同时学习一个编码器和解码器。通过最大化“证据下界”（ELBO）来近似计算数据的边际似然，并学习一个规整的隐空间。 | VAE (Variational Autoencoder) | **[Auto-Encoding Variational Bayes (2013)](https://arxiv.org/abs/1312.6114)** - *Diederik P. Kingma, et al.* |  
| | **能量模型 (Energy-based)** | 为每个数据点 $x$ 分配一个非归一化的标量**能量值** $E(x)$，能量越低表示该数据点越可能真实。 | EBM (Energy-Based Model) | **[A Tutorial on Energy-Based Learning (2006)](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf)** - *Yann LeCun, et al.* |  



好像还有一个薛定谔的桥理论，但是非主流方法，我对此了解也不深，所以没有写上去。后续会陆续讲解他们的原理，感兴趣的同学请follow me。